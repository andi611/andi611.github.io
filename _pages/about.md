---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Visit my new website: [**www.andytliu.com**](https://www.andytliu.com/)

# Table of Content
- [About Me](#about-me)
- [Publication](#publication)
- [Experience](#experience)
- [Honor](#honor)
- [Talk](#talk)
- [Project](#project)
- [During my spare time](#during-my-spare-time)

# About Me
My name is Andy T. Liu. I received my bachelor's degree in [Electrical Engineering (EE)](https://web.ee.ntu.edu.tw/eng/index.php) from National Taiwan University (NTU), Taipei, Taiwan, in 2018. I am currently working towards a Ph.D. degree with the College of [Electrical Engineering & Computer Science (EECS)](https://www.ntu.edu.tw/english/academics/academics_electrical.html), NTU, supervised by Professor [Hung-Yi Lee](https://speech.ee.ntu.edu.tw/~hylee/).  I’m a member of the “Speech Processing and Machine Learning Laboratory” at NTU, also working with Professor [Lin-shan Lee](http://speech.ee.ntu.edu.tw/previous_version/lslNew.htm).

My research interests include self-supervised learning, pre-training, and representation learning in the speech and NLP domain.  

My colleagues and I developed the [S3PRL toolkit](https://github.com/s3prl/s3prl), which provides an easy-to-use self-supervised toolkit, with unified interface for all kinds of self-supervised models and various downstream tasks.

**I have launched a new website. Please visit my new website for latest information: [www.andytliu.com](https://www.andytliu.com/)**

[Back](#table-of-content)

# Publication
*Sorted by recency

- **SUPERB: Speech processing Universal PERformance Benchmark**<br/>
    Shu-wen Yang, <u>Andy T Liu</u>, Po-Han Chi, Yung-Sung Chuang, Cheng-I Jeff Lai, Kushal Lakhotia, Yist Y Lin, Jiatong Shi, Xuankai Chang, Guan-Ting Lin, Tzu-Hsien Huang, Wei-Cheng Tseng, Ko-tik Lee, Da-Rong Liu, Zili Huang, Shuyan Dong, Shang-Wen Li, Shinji Watanabe, Abdelrahman Mohamed, Hung-yi Lee<br/>
    *Accepted by INTERSPEECH 2021, conference organized by the International Speech Communication Association (ISCA)*<br/>
    [ [to-be-presented-in-interspeech-2021](https://www.interspeech2021.org/) | [arxiv](https://arxiv.org/abs/2105.01051) | [pdf](https://arxiv.org/pdf/2105.01051.pdf) | [code](https://github.com/s3prl/s3prl) ]

- **Adversarial Defense for Automatic Speaker Verification by Cascaded Self-Supervised Learning Models**<br/>
    Haibin Wu, Xu Li, <u>Andy T. Liu</u>, Zhiyong Wu, Helen Meng, Hung-yi Lee<br/>
    *Virtual session in ICASSP 2021, conference organized by the IEEE Signal Processing Society (SPS)*<br/>
    [ [ieee](https://ieeexplore.ieee.org/document/9413737) | [arxiv](https://arxiv.org/abs/2102.07047) | [pdf](https://arxiv.org/pdf/2102.07047.pdf) | [code](https://github.com/s3prl/s3prl) ]

- **TERA: Self-Supervised Learning of Transformer Encoder Representation for Speech**<br/>
    <u>Andy T. Liu</u>, Shang-Wen Li, Hung-yi Lee<br/>
    *Published in IEEE/ACM TRANSACTIONS ON AUDIO, SPEECH, AND LANGUAGE PROCESSING, VOL. 29, 2021 (TASLP)*<br/>
    [ [ieee](https://ieeexplore.ieee.org/document/9478264) | [arxiv](https://arxiv.org/abs/2007.06028) | [pdf](https://bit.ly/ieee-tera-pdf) | [code](https://github.com/s3prl/s3prl) ]

- **Defense for Black-box Attacks on Anti-spoofing Models by Self-Supervised Learning**<br/>
    Haibin Wu, <u>Andy T. Liu</u>, Hung-yi Lee<br/>
    *Virtual session in INTERSPEECH 2020, conference organized by the International Speech Communication Association (ISCA)*<br/>
    [ [isca](https://www.isca-speech.org/archive/Interspeech_2020/abstracts/2026.html) | [arxiv](https://arxiv.org/abs/2006.03214) | [pdf](https://arxiv.org/pdf/2006.03214) | [code](https://github.com/s3prl/s3prl) ]

- **Understanding Self-Attention of Self-Supervised Audio Transformers**<br/>
    Shu-wen Yang, <u>Andy T. Liu</u>, Hung-yi Lee<br/>
    *Virtual session in INTERSPEECH 2020, conference organized by the International Speech Communication Association (ISCA)*<br/>
    [ [isca](https://www.isca-speech.org/archive/Interspeech_2020/abstracts/2231.html) | [arxiv](https://arxiv.org/abs/2006.03265) | [pdf](https://arxiv.org/pdf/2006.03265) | [demo](https://github.com/leo19941227/Self-Attention-on-SATs) ]

- **Towards Robust Neural Vocoding for Speech Generation: A Survey**<br/>
    Po-chun Hsu, Chun-hsuan Wang, <u>Andy T. Liu</u>, Hung-yi Lee<br/>
    *arXiv preprint, 2020, Cornell University*<br/>
    [ [arxiv](https://arxiv.org/abs/1912.02461) | [pdf](https://arxiv.org/pdf/1912.02461) | [demo](https://bogihsu.github.io/Robust-Neural-Vocoding/) ]

- **Mockingjay: Unsupervised Speech Representation Learning with Deep Bidirectional Transformer Encoders**<br/>
    <u>Andy T. Liu</u>, Shu-wen Yang, Po-Han Chi, Po-chun Hsu, Hung-yi Lee<br/>
    *Lecture session in ICASSP 2020, conference organized by the IEEE Signal Processing Society (SPS)*<br/>
    [ [ieee](https://ieeexplore.ieee.org/document/9054458) | [arxiv](https://arxiv.org/abs/1910.12638) | [pdf](https://bit.ly/ieee-mockingjay-pdf) | [code](https://github.com/andi611/Mockingjay-Speech-Representation) | [slide](https://bit.ly/icassp2020-mockingjay) | [talk](https://youtu.be/THylmb3hZVs) ]

- **Unsupervised End-to-End Learning of Discrete Linguistic Units for Voice Conversion**<br/>
    <u>Andy T. Liu</u>, Po-chun Hsu, Hung-yi Lee<br/>
    *Oral session in INTERSPEECH 2019, conference organized by the International Speech Communication Association (ISCA)*<br/>
    [ [isca](https://www.isca-speech.org/archive/Interspeech_2019/abstracts/2048.html) | [arxiv](https://arxiv.org/abs/1905.11563) | [pdf](https://arxiv.org/pdf/1905.11563) | [code](https://github.com/andi611/ZeroSpeech-TTS-without-T) | [slide](http://bit.ly/20190917_interspeech_talk) ]

[Back](#table-of-content)

# Experience
## Intern Experience
- **Applied Scientist Intern**<br/>
    [Amazon Web Services (AWS)](https://aws.amazon.com/)<br/>
    *During this internship, I worked on Question Answering (QA), Named Entity Recognition (NER), prompt-based fine-tuning in the NLP domain, and self-supervised learning (SSL) with speaker identification in the speech domain.*<br/>
    Remote, Jun. 2021 - Oct. 2021.

- **Ph.D. Researcher Intern**<br/>
    [ASUS Intelligent Cloud Services (AICS)](https://aics.asus.com/)<br/>
    *During this internship, I worked on unsupervised graph representation learning, particularly in the medical domain. I had the privilege of working with Professor [Chih-Jen Lin](https://www.csie.ntu.edu.tw/~cjlin/), and Professor [Victor Tsai](https://www.cs.nccu.edu.tw/~mftsai/).*<br/>
    Taipei, Sep. 2020 - Jun. 2021

[Back](#table-of-content)

## TA Experience
- <p style="display: flex; flex-direction: row; justify-content: space-between; margin: 0 0 0.5em;"><span style="flex: 0 0 auto">TA of <a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses.html">Machine Learning Special Project</a></span> <span style="flex:  0 0 auto"><i>NTU EECS, 2018-Pres.</i></span></p>
- <p style="display: flex; flex-direction: row; justify-content: space-between; margin: 0 0 0.5em;"><span style="flex: 0 0 auto">TA of <a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLDS18.html">Machine Learning and Having it Deep and Structured</a></span> <span style="flex:  0 0 auto"><i>NTU EECS, Fall 2019</i></span></p>

[Back](#table-of-content)

## Peer Review Experience
- <p style="display: flex; flex-direction: row; justify-content: space-between; margin: 0 0 0.5em;"><span style="flex: 0 0 auto">Reviewer of <a href="https://2021.emnlp.org/">EMNLP 2021</a></span> <span style="flex:  0 0 auto"><i>Conference, 2021</i></span></p>
- <p style="display: flex; flex-direction: row; justify-content: space-between; margin: 0 0 0.5em;"><span style="flex: 0 0 auto">Reviewer of <a href="https://neurips-sas-2020.github.io/">NeurIPS SAS Workshop 2020</a></span> <span style="flex:  0 0 auto"><i>Workshop, 2020</i></span></p>
- <p style="display: flex; flex-direction: row; justify-content: space-between; margin: 0 0 0.5em;"><span style="flex: 0 0 auto">Secondary Review Helper of <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6570655">IEEE/ACM TASLP</a></span> <span style="flex:  0 0 auto"><i>Journal, 2020</i></span></p>
- <p style="display: flex; flex-direction: row; justify-content: space-between; margin: 0 0 0.5em;"><span style="flex: 0 0 auto">Secondary Review Helper of <a href="http://www.iscslp2021.org/">ISCSLP 2020</a></span> <span style="flex:  0 0 auto"><i>Conference, 2020</i></span></p>
- <p style="display: flex; flex-direction: row; justify-content: space-between; margin: 0 0 0.5em;"><span style="flex: 0 0 auto">Secondary Review Helper of <a href="https://aaai.org/Conferences/AAAI-20/">AAAI 2020</a></span> <span style="flex:  0 0 auto"><i>Conference, 2020</i></span></p>
- <p style="display: flex; flex-direction: row; justify-content: space-between; margin: 0 0 0.5em;"><span style="flex: 0 0 auto">Secondary Review Helper of <a href="https://aaai.org/Conferences/AAAI-19/">AAAI 2019</a></span> <span style="flex:  0 0 auto"><i>Conference, 2019</i></span></p>
- <p style="display: flex; flex-direction: row; justify-content: space-between; margin: 0 0 0.5em;"><span style="flex: 0 0 auto">Secondary Review Helper of <a href="https://2020.ieeeicassp.org/">IEEE SPS ICASSP 2020</a></span> <span style="flex:  0 0 auto"><i>Conference, 2019</i></span></p>
- <p style="display: flex; flex-direction: row; justify-content: space-between; margin: 0 0 0.5em;"><span style="flex: 0 0 auto">Secondary Review Helper of <a href="https://interspeech2019.org/">ISCA INTERSPEECH 2019</a></span> <span style="flex:  0 0 auto"><i>Conference, 2019</i></span></p>
- <p style="display: flex; flex-direction: row; justify-content: space-between; margin: 0 0 0.5em;"><span style="flex: 0 0 auto">Secondary Review Helper of <a href="http://www.wikicfp.com/cfp/servlet/event.showcfp?eventid=87194&copyownerid=13881">ACMSE 2019</a></span> <span style="flex:  0 0 auto"><i>Conference, 2019</i></span></p>

[Back](#table-of-content)

# Honor
- <p style="display: flex; flex-direction: row; justify-content: space-between; margin: 0 0 0.5em;"><span style="flex: 0 0 auto">Merry Electro-Acoustic Thesis Award - 1st Place (美律電聲論文獎 - 金質獎)</span> <span style="flex:  0 0 auto"><i>2020</i></span></p>
- <p style="display: flex; flex-direction: row; justify-content: space-between; margin: 0 0 0.5em;"><span style="flex: 0 0 auto">ASUS AICS Ph.D. Scholarship (華碩AI研發中心博士生學位計畫)</span> <span style="flex:  0 0 auto"><i>Sep. 2020 - Jun. 2021</i></span></p>
- <p style="display: flex; flex-direction: row; justify-content: space-between; margin: 0 0 0.5em;"><span style="flex: 0 0 auto">NTU Frontier Speech Technology Scholarship (國立臺灣大學前瞻語音科技獎學金)</span> <span style="flex:  0 0 auto"><i>Oct. 2019 - Aug. 2020</i></span></p>
- <p style="display: flex; flex-direction: row; justify-content: space-between; margin: 0 0 0.5em;"><span style="flex: 0 0 auto">FAOS Outstanding Students Conference Travel Grant (傑出人才優秀學生出國開會補助)</span> <span style="flex:  0 0 auto"><i>2019</i></span></p>
- <p style="display: flex; flex-direction: row; justify-content: space-between; margin: 0 0 0.5em;"><span style="flex: 0 0 auto">NTU Electrical Engineering Innovation Award - 2nd place (國立臺灣大學電機系精專獎 - 貳獎)</span> <span style="flex:  0 0 auto"><i>2017</i></span></p>
- <p style="display: flex; flex-direction: row; justify-content: space-between; margin: 0 0 0.5em;"><span style="flex: 0 0 auto">Macau Government Lotus Award (澳門政府蓮花獎)</span> <span style="flex:  0 0 auto"><i>2014</i></span></p>

[Back](#table-of-content)

# Talk
- [Audio BERT](https://youtu.be/NN9Q9Jhtvvg), *Deep Learning for Human Language Processing Course, NTUEE, Taipei, Taiwan, June 2020*
- [Self-Supervised Learning for Speech](files/20200514_asus_aics_SSL_for_speech.pdf), *ASUS Inc., Taipei, Taiwan, May 2020*
- [Mockingjay: Unsupervised Speech Representation Learning with Deep Bidirectional Transformer Encoders](files/20200507_icassp_Mockingjay.pdf), *ICASSP, Virtual, Online, May 2020*
- [Mockingjay: Unsupervised Speech Representation Learning with Deep Bidirectional Transformer Encoders](files/20200207_NTU_foreign_guest.pdf), *NTU, Taipei, Taiwan, February 2020*
- [Unsupervised End-to-End Learning of Discrete Linguistic Units for Voice Conversion](files/20190917_interspeech_zerospeech.pdf), *Interspeech, Graz, Austria, September 2019*

[Back](#table-of-content)

# Project

- The S3PRL Toolkit: Self-Supervised Speech Pre-training and Representation Learning [ [repo](https://github.com/s3prl/s3prl) ![GitHub stars](https://img.shields.io/github/stars/s3prl/s3prl?style=social&label=Star&maxAge=2592000) ]
- SUPERB: Speech processing Universal PERformance Benchmark [ [website](https://superbbenchmark.org/) ![GitHub stars](https://img.shields.io/github/stars/s3prl/s3prl?style=social&label=Star&maxAge=2592000) ]
- ZeroSpeech TTS-without-T Challenge [ [repo](https://github.com/andi611/ZeroSpeech-TTS-without-T) ]
- Tacotron English TTS [ [repo](https://github.com/andi611/TTS-Tacotron-Pytorch) ]
- Tacotron Code-Switch TTS [ [repo](https://github.com/andi611/CS-Tacotron-Pytorch) ]
- Sequence GAN Chatbot [ [repo](https://github.com/andi611/Conditional-SeqGAN-Tensorflow) ]

[Back](#table-of-content)

# During my spare time
- Scuba Diving ([PADI](https://www.padi.com/courses/open-water-diver?lang=en)), Jul. 2020 - Present
- Guitar, Amateur, Oct. 2016 - Jan. 2020
- Road Biking, ([NTU Cycling Club](https://www.facebook.com/ntucyc)), Jun. 2014 - Aug. 2017
- I also have several pet geckos: [Instagram](https://www.instagram.com/smiling._.dragons/)

[Back](#table-of-content)

# Contact
[tingweiandyliu@gmail.com](mailto:tingweiandyliu@gmail.com)

Write me if you are looking for a collaboration!
